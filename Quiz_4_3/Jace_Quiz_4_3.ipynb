{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lecture, we will build a neural network from scratch and code how it performs predictions using forward propagation. Please note that all deep learning libraries have the entire training and prediction processes implemented, and so in practice you wouldn't really need to build a neural network from scratch. However, hopefully completing this lab will help you understand neural networks and how they work even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "From the lectures, let's recap how a neural network makes predictions through the forward propagation process. Here is a neural network that takes two inputs, has one hidden layer with two nodes, and an output layer with one node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://cocl.us/neural_network_example\" alt=\"Neural Network Example\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start by randomly initializing the weights and the biases in the network. We have 6 weights and 3 biases, one for each node in the hidden layer as well as for each node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # import Numpy library to generate \n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2) # initialize the weights\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2) # initialize the biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's print the weights and biases for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94 0.08 0.12 0.86 0.71 0.33]\n",
      "[0.02 0.34 0.61]\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that we have the weights and the biases defined for the network, let's compute the output for a given input, $x_1$ and $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5 # input 1\n",
    "x_2 = 0.85 # input 2\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start by computing the wighted sum of the inputs, $z_{1, 1}$, at the first node of the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jace Marden knew that the weighted sum of the inputs at the first node in the hidden layer is 0.558\n"
     ]
    }
   ],
   "source": [
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "\n",
    "print('Jace Marden knew that the weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, let's compute the weighted sum of the inputs, $z_{1, 2}$, at the second node of the hidden layer. Assign the value to **z_12**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### type code here\n",
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Print the weighted sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jace Marden knew that the weighted sum of the inputs at the second node in the hidden layer is 1.131\n"
     ]
    }
   ],
   "source": [
    "print('Jace Marden knew that the weighted sum of the inputs at the second node in the hidden layer is {}'.format(np.around(z_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, assuming a **sigmoid** activation function, let's compute the activation of the first node, $a_{1, 1}$, in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.636\n"
     ]
    }
   ],
   "source": [
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's also compute the activation of the second node, $a_{1, 2}$, in the hidden layer. Assign the value to **a_12**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.756\n"
     ]
    }
   ],
   "source": [
    "### type code here\n",
    "\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Print the activation of the second node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the second node in the hidden layer is 0.756\n"
     ]
    }
   ],
   "source": [
    "print('The activation of the second node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now these activations will serve as the inputs to the output layer. So, let's compute the weighted sum of these inputs to the node in the output layer. Assign the value to **z_2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### type code here\n",
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Print the weighted sum of the inputs at the node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the inputs at the node in the output layer is 1.311\n"
     ]
    }
   ],
   "source": [
    "print('The weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, let's compute the output of the network as the activation of the node in the output layer. Assign the value to **a_2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### type code here\n",
    "a_2 = 1.0/(1.0 + np.exp(-z_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Print the activation of the node in the output layer which is equivalent to the prediction made by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1 = 0.5 and x2 = 0.85 is 0.7877\n"
     ]
    }
   ],
   "source": [
    "print('The output of the network for x1 = 0.5 and x2 = 0.85 is {}'.format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Obviously, neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to code an automatic way of making predictions, let's generalize our network. A general network would take $n$ inputs, would have many hidden layers, each hidden layer having $m$ nodes, and would have an output layer. Although the network is showing one hidden layer, but we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item12'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Practice: Initialize a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start by formally defining the structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "n = 2 # number of inputs\n",
    "num_hidden_layers = 2 # number of hidden layers\n",
    "m = [2, 2] # number of nodes in each hidden layer\n",
    "num_nodes_output = 2 # number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that we defined the structure of the network, let's go ahead and inititailize the weights and the biases in the network to random numbers. In order to be able to initialize the weights and the biases to random numbers, we will need to import the **Numpy** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.29, 0.79]), 'bias': array([0.57])}, 'node_2': {'weights': array([0.02, 0.25]), 'bias': array([0.59])}}, 'layer_2': {'node_1': {'weights': array([0.12, 0.22]), 'bias': array([0.97])}, 'node_2': {'weights': array([0.94, 0.2 ]), 'bias': array([0.28])}}, 'output': {'node_1': {'weights': array([0.39, 0.66]), 'bias': array([0.31])}, 'node_2': {'weights': array([0.08, 0.63]), 'bias': array([0.95])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n # number of nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network an an empty dictionary\n",
    "\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_hidden_layers + 1): \n",
    "    \n",
    "    # determine name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Awesome! So now with the above code, we are able to initialize the weights and the biases pertaining to any network of any number of hidden layers and number of nodes in each layer. But let's put this code in a function so that we are able to repetitively execute all this code whenever we want to construct a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Use the *initialize_network* function to create a network that:\n",
    "\n",
    "1. takes 5 inputs\n",
    "2. has three hidden layers\n",
    "3. has 3 nodes in the first layer, 2 nodes in the second layer, and 3 nodes in the third layer\n",
    "4. has 1 node in the output layer\n",
    "\n",
    "Call the small network **Network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': {'node_1': {'weights': array([0.29, 0.3 , 0.83, 0.52, 0.46]),\n",
       "   'bias': array([0.64])},\n",
       "  'node_2': {'weights': array([0.9 , 0.48, 0.87, 0.84, 0.25]),\n",
       "   'bias': array([0.68])},\n",
       "  'node_3': {'weights': array([0.46, 0.22, 0.7 , 0.2 , 0.65]),\n",
       "   'bias': array([0.92])}},\n",
       " 'layer_2': {'node_1': {'weights': array([0.37, 0.09, 0.79]),\n",
       "   'bias': array([0.46])},\n",
       "  'node_2': {'weights': array([0.86, 0.81, 0.05]), 'bias': array([0.6])}},\n",
       " 'layer_3': {'node_1': {'weights': array([0.81, 0.1 ]), 'bias': array([0.33])},\n",
       "  'node_2': {'weights': array([0.18, 0.48]), 'bias': array([0.13])},\n",
       "  'node_3': {'weights': array([0.07, 0.79]), 'bias': array([0.19])}},\n",
       " 'output': {'node_1': {'weights': array([0.15, 1.  , 0.49]),\n",
       "   'bias': array([0.62])}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### type code here\n",
    "network = initialize_network(5, 3, [3,2,3], 1)\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"item3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item13'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Compute Weighted Sum at Each Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The weighted sum at each node is computed as the dot product of the inputs and the weights plus the bias. So let's create a function called *compute_weighted_sum* that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "#     return np.sum(np.dot(inputs,weights)) + bias\n",
    "    return np.sum(inputs * weights) + bias\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's generate 5 inputs that we can feed to **small_network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Use the *compute_weighted_sum* function to compute the weighted sum at the first node in the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum at the first node in the hidden layer is 1.4015\n"
     ]
    }
   ],
   "source": [
    "### type code here\n",
    "weighted_sum = compute_weighted_sum(inputs ,network['layer_1']['node_1']['weights'],network['layer_1']['node_1']['bias'])\n",
    "print('The weighted sum at the first node in the hidden layer is {}'.format(np.around(weighted_sum[0], decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"item4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item14'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Compute Node Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Recall that the output of each node is simply a non-linear tranformation of the weighted sum. We use activation functions for this mapping. Let's use the sigmoid function as the activation function here. So let's define a function that takes a weighted sum as input and returns the non-linear transformation of the input using the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Use the *node_activation* function to compute the output of the first node in the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jace Marden + The output of the first node in the hidden layer is 0.8024\n"
     ]
    }
   ],
   "source": [
    "### type your answer here\n",
    "node_weights = network['layer_1']['node_1']['weights']\n",
    "node_bias = network['layer_1']['node_1']['bias']\n",
    "node_output = node_activation(compute_weighted_sum(inputs, node_weights, node_bias))\n",
    "print('Jace Marden + The output of the first node in the hidden layer is {}'.format(np.around(node_output[0], decimals=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"item5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item15'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The final piece of building a neural network that can perform predictions is to put everything together. So let's create a function that applies the *compute_weighted_sum* and *node_activation* functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The way we are going to accomplish this is through the following procedure:\n",
    "\n",
    "1. Start with the input layer as the input to the first hidden layer.\n",
    "2. Compute the weighted sum at the nodes of the current layer.\n",
    "3. Compute the output of the nodes of the current layer.\n",
    "4. Set the output of the current layer to be the input to the next layer.\n",
    "5. Move to the next layer in the network.\n",
    "5. Repeat steps 2 - 4 until we compute the output of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Use the *forward_propagate* function to compute the prediction of our small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [np.float64(0.8024), np.float64(0.8634), np.float64(0.8094)]\n",
      "The outputs of the nodes in hidden layer number 2 is [np.float64(0.8137), np.float64(0.8839)]\n",
      "The outputs of the nodes in hidden layer number 3 is [np.float64(0.746), np.float64(0.6684), np.float64(0.7202)]\n",
      "The predicted value by the network for the given input is [0.8524]\n"
     ]
    }
   ],
   "source": [
    "### type your answser here\n",
    "# print(inputs)\n",
    "predictions = forward_propagate(network, inputs)\n",
    "print('The predicted value by the network for the given input is {}'.format(np.around(predictions, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': {'node_1': {'weights': array([0.29, 0.3 , 0.83, 0.52, 0.46]),\n",
       "   'bias': array([0.64])},\n",
       "  'node_2': {'weights': array([0.9 , 0.48, 0.87, 0.84, 0.25]),\n",
       "   'bias': array([0.68])},\n",
       "  'node_3': {'weights': array([0.46, 0.22, 0.7 , 0.2 , 0.65]),\n",
       "   'bias': array([0.92])}},\n",
       " 'layer_2': {'node_1': {'weights': array([0.37, 0.09, 0.79]),\n",
       "   'bias': array([0.46])},\n",
       "  'node_2': {'weights': array([0.86, 0.81, 0.05]), 'bias': array([0.6])}},\n",
       " 'layer_3': {'node_1': {'weights': array([0.81, 0.1 ]), 'bias': array([0.33])},\n",
       "  'node_2': {'weights': array([0.18, 0.48]), 'bias': array([0.13])},\n",
       "  'node_3': {'weights': array([0.07, 0.79]), 'bias': array([0.19])}},\n",
       " 'output': {'node_1': {'weights': array([0.15, 1.  , 0.49]),\n",
       "   'bias': array([0.62])}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to store the activations of each layer, we can convert our forward_propagation as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Define the forward propagation\n",
    "def forward_propagationS(network, inputs):\n",
    "    \"\"\"\n",
    "    Perform forward propagation through the network.\n",
    "    Arguments:\n",
    "        inputs: Input array.\n",
    "        network: Network dictionary with weights and biases.\n",
    "    Returns:\n",
    "        activations: List of activations for all layers.\n",
    "    \"\"\"\n",
    "    activations = [inputs]  # Start with the input layer\n",
    "    for layer in network.values():\n",
    "        z = []\n",
    "        a = []\n",
    "        for node in layer.values():\n",
    "            z_value = np.dot(activations[-1], node['weights']) + node['bias']\n",
    "            z.append(z_value)\n",
    "            a.append(sigmoid(z_value))\n",
    "        activations.append(np.array(a).flatten())\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.15, 0.74, 0.26, 0.53, 0.01]),\n",
       " array([0.80242181, 0.86343289, 0.80942835]),\n",
       " array([0.8136727 , 0.88390439]),\n",
       " array([0.74601402, 0.66835075, 0.72015721]),\n",
       " array([0.85234714])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_s = forward_propagationS(network, inputs)\n",
    "predictions_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So we built the code to define a neural network. We can specify the number of inputs that a neural network can take, the number of hidden layers as well as the number of nodes in each hidden layer, and the number of nodes in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Please use the *initialize_network* to create your neural network and define its weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "my_network = initialize_network(5, 3, [2, 3, 2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, for a given input,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = np.around(np.random.uniform(size=5), decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "we compute the network predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [np.float64(0.8857), np.float64(0.8889)]\n",
      "The outputs of the nodes in hidden layer number 2 is [np.float64(0.7822), np.float64(0.6965), np.float64(0.7411)]\n",
      "The outputs of the nodes in hidden layer number 3 is [np.float64(0.868), np.float64(0.881)]\n",
      "The predicted values by the network for the given input are [np.float64(0.8952), np.float64(0.8222), np.float64(0.8035)]\n"
     ]
    }
   ],
   "source": [
    "predictions = forward_propagate(my_network, inputs)\n",
    "print('The predicted values by the network for the given input are {}'.format(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Feel free to play around with the code by creating different networks of different structures and enjoy making predictions using the *forward_propagate* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation - Slides Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward propagation (backpropagation) is the process of computing gradients to adjust the weights and biases of a neural network, using the chain rule of differentiation. It is essential for training neural networks via optimization algorithms like gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following example to derive and build the Backward Propagation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Slide example](https://raw.githubusercontent.com/Shangyue-CWU/CS457Draft/refs/heads/main/Neural_Example1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial network parameters\n",
    "inputs = np.array([0.1, 0.5])  # Input values i1 and i2\n",
    "\n",
    "w1, w2, w3, w4 = 0.1, 0.2, 0.3, 0.4  # Weights from input to hidden\n",
    "w5, w6, w7, w8 = 0.5, 0.6, 0.7, 0.8  # Weights from hidden to output\n",
    "\n",
    "b1  = 0.25  # Biases for the hidden layer\n",
    "b2 = 0.35 # Biases for the output layer\n",
    "outputs = np.array([0.05, 0.95])  # True output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "# Hidden layer\n",
    "z_h1 = w1 * inputs[0] + w3 * inputs[1] + b1\n",
    "z_h2 = w2 * inputs[0] + w4 * inputs[1] + b1\n",
    "h1 = sigmoid(z_h1)\n",
    "h2 = sigmoid(z_h2)\n",
    "\n",
    "# Output layer\n",
    "z_o1 = w5 * h1 + w7 * h2 + b2\n",
    "z_o2 = w6 * h1 + w8 * h2 + b2\n",
    "o1 = sigmoid(z_o1)\n",
    "o2 = sigmoid(z_o2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check parameters: 0.6967422944416473 0.18911824013367143 0.6010878788483698 0.07920335211124074\n",
      "Updated w5: 0.45247798873325557\n"
     ]
    }
   ],
   "source": [
    "# Backward Propagation\n",
    "# Define sigmoid derivative function\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Compute errors at the output\n",
    "error_o1 = o1 - outputs[0]\n",
    "error_o2 = o2 - outputs[1]\n",
    "\n",
    "# Gradients for output layer weights\n",
    "d_w5 = error_o1 * sigmoid_derivative(o1) * h1\n",
    "d_w6 = error_o2 * sigmoid_derivative(o2) * h1\n",
    "d_w7 = error_o1 * sigmoid_derivative(o1) * h2\n",
    "d_w8 = error_o2 * sigmoid_derivative(o2) * h2\n",
    "\n",
    "\n",
    "print(\"Check parameters:\", error_o1 , sigmoid_derivative(o1) , h1,d_w5)\n",
    "\n",
    "learning_rate = 0.6\n",
    "# Update w5, w6, w7, 8\n",
    "w5 = w5 - learning_rate * d_w5\n",
    "w6 = w6 - learning_rate * d_w6\n",
    "w7 = w7 - learning_rate * d_w7\n",
    "w8 = w8 - learning_rate * d_w8\n",
    "\n",
    "\n",
    "print(\"Updated w5:\", w5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6115908974377722),\n",
       " np.float64(0.6513477565699334),\n",
       " np.float64(0.8118665676953379))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w6,w7,w8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated w1: 0.0994250169757827\n",
      "Updated w2: 0.199151711181407\n",
      "Updated w3: 0.2971250848789134\n",
      "Updated w4: 0.39575855590703507\n"
     ]
    }
   ],
   "source": [
    "# Backward Propagation for w1, w2, w3, w4\n",
    "# Deltas for output layer\n",
    "delta_o1 = (o1 - outputs[0]) * sigmoid_derivative(o1)\n",
    "delta_o2 = (o2 - outputs[1]) * sigmoid_derivative(o2)\n",
    "\n",
    "# Deltas for hidden layer\n",
    "delta_h1 = (delta_o1 * w5 + delta_o2 * w6) * sigmoid_derivative(h1)\n",
    "delta_h2 = (delta_o1 * w7 + delta_o2 * w8) * sigmoid_derivative(h2)\n",
    "\n",
    "# Gradients for input-to-hidden weights\n",
    "d_w1 = delta_h1 * inputs[0]\n",
    "d_w2 = delta_h2 * inputs[0]\n",
    "d_w3 = delta_h1 * inputs[1]\n",
    "d_w4 = delta_h2 * inputs[1]\n",
    "\n",
    "# Update weights\n",
    "w1 = w1 - learning_rate * d_w1\n",
    "w2 = w2 - learning_rate * d_w2\n",
    "w3 = w3 - learning_rate * d_w3\n",
    "w4 = w4 - learning_rate * d_w4\n",
    "\n",
    "# Print updated weights\n",
    "print(\"Updated w1:\", w1)\n",
    "print(\"Updated w2:\", w2)\n",
    "print(\"Updated w3:\", w3)\n",
    "print(\"Updated w4:\", w4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the above idea into a standard back-propagation function and feed back the weight of each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation_with_updates(network, activations, y_true, learning_rate):\n",
    "    \"\"\"\n",
    "    Perform backpropagation to calculate gradients and update weights for each layer.\n",
    "    Arguments:\n",
    "        network: Dictionary containing layers with weights and biases.\n",
    "        activations: List of activations from forward propagation.\n",
    "        y_true: Ground truth labels.\n",
    "        learning_rate: Learning rate for weight updates.\n",
    "    Returns:\n",
    "        network: Updated network with modified weights and biases.\n",
    "    \"\"\"\n",
    "\n",
    "    print(network)\n",
    "    print(activations)\n",
    "    print(y_true)\n",
    "    print(learning_rate)\n",
    "    \n",
    "    # Step 1: Compute deltas for the output layer\n",
    "    # Calculate the error (delta) for the output layer by comparing the predicted output (activations[-1])\n",
    "    # with the true labels (y_true) and applying the derivative of the activation function.\n",
    "    delta_output = (activations[-1] - y_true) * sigmoid_derivative(activations[-1])\n",
    "\n",
    "    # Step 2: Backpropagate through each layer\n",
    "    # Iterate through the layers in reverse order (from output to input)\n",
    "    for layer_idx in reversed(range(len(network))):\n",
    "        # Get the current layer's name and data\n",
    "        layer_name = list(network.keys())[layer_idx]\n",
    "        current_layer = network[layer_name]\n",
    "\n",
    "        if layer_name == 'output':\n",
    "            # For the output layer, use the precomputed delta\n",
    "            delta = delta_output\n",
    "        else:\n",
    "            # For hidden layers, compute the delta by propagating the error backward\n",
    "            # Multiply the current delta with the weights of the next layer (transposed),\n",
    "            # then apply the derivative of the activation function.\n",
    "            \n",
    "            next_layer_name = list(network.keys())[layer_idx + 1]\n",
    "            next_layer = network[next_layer_name]\n",
    "            weight_matrix = np.array([node['weights'] for node in next_layer.values()])\n",
    "#             print('weight_matrix:',weight_matrix)\n",
    "            \n",
    "            #Apply the derivative of the activation function to scale the delta for the current layer.\n",
    "            # This ensures the gradient respects the activation function's behavior.\n",
    "            delta = np.dot(delta, weight_matrix.T) * sigmoid_derivative(activations[layer_idx + 1])\n",
    "\n",
    "        # Loop through each node in the current layer\n",
    "        for node_idx, (node_name, node_data) in enumerate(current_layer.items()):\n",
    "            # Get the activations from the previous layer (or input for the first hidden layer)\n",
    "            a_prev = activations[layer_idx]\n",
    "            \n",
    "            # Compute the gradients for weights (dW) and biases (db)\n",
    "            dW = delta[node_idx] * a_prev  # Gradient of weights\n",
    "            db = delta[node_idx]           # Gradient of biases\n",
    "\n",
    "            # Update weights and biases using gradient descent\n",
    "            current_layer[node_name]['weights'] -= learning_rate * dW  # Update weights\n",
    "            current_layer[node_name]['bias'] -= learning_rate * db     # Update bias\n",
    "\n",
    "    # Return the updated network with modified weights and biases\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our backpropagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activations with the first forward pass:  [array([0.5, 0.2, 0.1]), array([0.76242124, 0.79183137, 0.79363873, 0.84461828]), array([0.79402928, 0.80558957, 0.92695533]), array([0.79402677])]\n",
      "{'layer_1': {'node_1': {'weights': array([0.59, 0.99, 0.43]), 'bias': array([0.63])}, 'node_2': {'weights': array([0.78, 0.26, 0.64]), 'bias': array([0.83])}, 'node_3': {'weights': array([0.52, 0.42, 0.53]), 'bias': array([0.95])}, 'node_4': {'weights': array([1.  , 0.67, 0.79]), 'bias': array([0.98])}}, 'layer_2': {'node_1': {'weights': array([0.14, 0.03, 0.75, 0.62]), 'bias': array([0.1])}, 'node_2': {'weights': array([0.52, 0.51, 0.29, 0.25]), 'bias': array([0.18])}, 'node_3': {'weights': array([0.58, 0.15, 0.71, 0.86]), 'bias': array([0.69])}}, 'output': {'node_1': {'weights': array([0.27, 0.4 , 0.51]), 'bias': array([0.34])}}}\n",
      "[array([0.5, 0.2, 0.1]), array([0.76242124, 0.79183137, 0.79363873, 0.84461828]), array([0.79402928, 0.80558957, 0.92695533]), array([0.79402677])]\n",
      "[1]\n",
      "0.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,) and (3,1) not aligned: 1 (dim 0) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations with the first forward pass: \u001b[39m\u001b[38;5;124m\"\u001b[39m, activations)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Perform backpropagation and weight updates\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m updated_network \u001b[38;5;241m=\u001b[39m \u001b[43mbackpropagation_with_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Print updated weights and biases\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJace Marden + Updated Weights and Biases:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 45\u001b[0m, in \u001b[0;36mbackpropagation_with_updates\u001b[1;34m(network, activations, y_true, learning_rate)\u001b[0m\n\u001b[0;32m     40\u001b[0m             weight_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m next_layer\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#             print('weight_matrix:',weight_matrix)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m             \n\u001b[0;32m     43\u001b[0m             \u001b[38;5;66;03m#Apply the derivative of the activation function to scale the delta for the current layer.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m             \u001b[38;5;66;03m# This ensures the gradient respects the activation function's behavior.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m             delta \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sigmoid_derivative(activations[layer_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# Loop through each node in the current layer\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node_idx, (node_name, node_data) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(current_layer\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m     49\u001b[0m             \u001b[38;5;66;03m# Get the activations from the previous layer (or input for the first hidden layer)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,) and (3,1) not aligned: 1 (dim 0) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Example inputs\n",
    "network = initialize_network(3, 2, [4, 3], 1)\n",
    "inputs = np.array([0.5, 0.2, 0.1])\n",
    "y_true = np.array([1])  # Target output\n",
    "learning_rate = 0.1  # Learning rate\n",
    "\n",
    "# Perform forward propagation\n",
    "activations = forward_propagationS(network,inputs)\n",
    "print(\"activations with the first forward pass: \", activations)\n",
    "\n",
    "# Perform backpropagation and weight updates\n",
    "updated_network = backpropagation_with_updates(network, activations, y_true, learning_rate)\n",
    "\n",
    "# Print updated weights and biases\n",
    "print(\"Jace Marden + Updated Weights and Biases:\")\n",
    "for layer_name, layer_nodes in updated_network.items():\n",
    "    print(f\"Layer: {layer_name}\")\n",
    "    for node_name, node_data in layer_nodes.items():\n",
    "        print(f\"  Node: {node_name}, Weights: {node_data['weights']}, Bias: {node_data['bias']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the change of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.0994434, 0.297217 ]), 'bias': array([0.244434])}, 'node_2': {'weights': array([0.19922611, 0.39613053]), 'bias': array([0.24226106])}}, 'output': {'node_1': {'weights': array([0.45247799, 0.65134776]), 'bias': array([0.27093999])}, 'node_2': {'weights': array([0.6115909 , 0.81186657]), 'bias': array([0.3692832])}}}\n",
      "[array([0.1, 0.5]), array([0.59940507, 0.61307323]), array([0.71939881, 0.77444935])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09892293, 0.29461463]), 'bias': array([0.23922925])}, 'node_2': {'weights': array([0.19838791, 0.39193956]), 'bias': array([0.23387911])}}, 'output': {'node_1': {'weights': array([0.40388028, 0.60164188]), 'bias': array([0.18986342])}, 'node_2': {'weights': array([0.62261926, 0.82314641]), 'bias': array([0.38768205])}}}\n",
      "[array([0.1, 0.5]), array([0.59782935, 0.61056498]), array([0.68968699, 0.77945385])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09845551, 0.29227753]), 'bias': array([0.23455505])}, 'node_2': {'weights': array([0.19750008, 0.38750041]), 'bias': array([0.22500081])}}, 'output': {'node_1': {'weights': array([0.35477275, 0.55148821]), 'bias': array([0.10772037])}, 'node_2': {'weights': array([0.6331355 , 0.83388668]), 'bias': array([0.40527275])}}}\n",
      "[array([0.1, 0.5]), array([0.59641253, 0.6079018 ]), array([0.65803775, 0.784114  ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09805463, 0.29027315]), 'bias': array([0.23054631])}, 'node_2': {'weights': array([0.19658052, 0.38290261]), 'bias': array([0.21580521])}}, 'output': {'node_1': {'weights': array([0.30581094, 0.5015832 ]), 'bias': array([0.0256265])}, 'node_2': {'weights': array([0.64318424, 0.84412899]), 'bias': array([0.42212139])}}}\n",
      "[array([0.1, 0.5]), array([0.59519614, 0.60513666]), array([0.62508079, 0.78847467])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09772887, 0.28864435]), 'bias': array([0.2272887])}, 'node_2': {'weights': array([0.19564897, 0.37824484]), 'bias': array([0.20648968])}}, 'output': {'node_1': {'weights': array([0.25768114, 0.45264957]), 'bias': array([-0.05523727])}, 'node_2': {'weights': array([0.65280483, 0.85391027]), 'bias': array([0.43828513])}}}\n",
      "[array([0.1, 0.5]), array([0.5942068 , 0.60232857]), array([0.5915852 , 0.79257557])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09748114, 0.28740572]), 'bias': array([0.22481143])}, 'node_2': {'weights': array([0.19472505, 0.37362523]), 'bias': array([0.19725045])}}, 'output': {'node_1': {'weights': array([0.21102869, 0.40535946]), 'bias': array([-0.13374941])}, 'node_2': {'weights': array([0.66203186, 0.86326341]), 'bias': array([0.45381343])}}}\n",
      "[array([0.1, 0.5]), array([0.59345395, 0.59953682]), array([0.55836135, 0.79645071])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09730901, 0.28654507]), 'bias': array([0.22309015])}, 'node_2': {'weights': array([0.19382627, 0.36913137]), 'bias': array([0.18826275])}}, 'output': {'node_1': {'weights': array([0.16639187, 0.36026512]), 'bias': array([-0.20896471])}, 'node_2': {'weights': array([0.67089555, 0.87221795]), 'bias': array([0.4687492])}}}\n",
      "[array([0.1, 0.5]), array([0.59293058, 0.59681485]), array([0.52615253, 0.80012828])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09720586, 0.28602928]), 'bias': array([0.22205857])}, 'node_2': {'weights': array([0.19296659, 0.36483294]), 'bias': array([0.17966588])}}, 'output': {'node_1': {'weights': array([0.12415892, 0.3177555 ]), 'bias': array([-0.28019219])}, 'node_2': {'weights': array([0.67942234, 0.8808006 ]), 'bias': array([0.48312996])}}}\n",
      "[array([0.1, 0.5]), array([0.59261682, 0.59420566]), array([0.49554977, 0.80363086])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09716247, 0.28581234]), 'bias': array([0.22162468])}, 'node_2': {'weights': array([0.19215564, 0.36077822]), 'bias': array([0.17155644])}}, 'output': {'node_1': {'weights': array([0.08455602, 0.27804642]), 'bias': array([-0.34701936])}, 'node_2': {'weights': array([0.68763539, 0.88903567]), 'bias': array([0.49698892])}}}\n",
      "[array([0.1, 0.5]), array([0.59248483, 0.59173952]), array([0.46695072, 0.80697609])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09716865, 0.28584327]), 'bias': array([0.22168654])}, 'node_2': {'weights': array([0.19139895, 0.35699473]), 'bias': array([0.16398947])}}, 'output': {'node_1': {'weights': array([0.04766237, 0.24119918]), 'bias': array([-0.40928872])}, 'node_2': {'weights': array([0.6955551 , 0.89694541]), 'bias': array([0.51035585])}}}\n",
      "[array([0.1, 0.5]), array([0.59250364, 0.58943416]), array([0.44056298, 0.81017767])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09721444, 0.2860722 ]), 'bias': array([0.22214441])}, 'node_2': {'weights': array([0.1906985 , 0.35349249]), 'bias': array([0.15698499])}}, 'output': {'node_1': {'weights': array([0.01344138, 0.20715547]), 'bias': array([-0.46704531])}, 'node_2': {'weights': array([0.70319955, 0.90455026]), 'bias': array([0.5232578])}}}\n",
      "[array([0.1, 0.5]), array([0.59264293, 0.58729667]), array([0.4164369, 0.8132463])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09729083, 0.28645415]), 'bias': array([0.2229083])}, 'node_2': {'weights': array([0.19005369, 0.35026846]), 'bias': array([0.15053692])}}, 'output': {'node_1': {'weights': array([-0.0182237 ,  0.17577605]), 'bias': array([-0.52047559])}, 'node_2': {'weights': array([0.71058496, 0.91186905]), 'bias': array([0.53571963])}}}\n",
      "[array([0.1, 0.5]), array([0.59287527, 0.58532606]), array([0.39450997, 0.81619061])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09739014, 0.28695069]), 'bias': array([0.22390139])}, 'node_2': {'weights': array([0.18946217, 0.34731087]), 'bias': array([0.14462173])}}, 'output': {'node_1': {'weights': array([-0.04749765,  0.14687485]), 'bias': array([-0.56985183])}, 'node_2': {'weights': array([0.71772599, 0.91891915]), 'bias': array([0.54776436])}}}\n",
      "[array([0.1, 0.5]), array([0.59317727, 0.58351589]), array([0.37464922, 0.81901778])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09750606, 0.28753031]), 'bias': array([0.22506063])}, 'node_2': {'weights': array([0.18892056, 0.34460281]), 'bias': array([0.13920563])}}, 'output': {'node_1': {'weights': array([-0.0745683 ,  0.12024511]), 'bias': array([-0.61548852])}, 'node_2': {'weights': array([0.72463597, 0.92571659]), 'bias': array([0.55941347])}}}\n",
      "[array([0.1, 0.5]), array([0.5935297 , 0.58185648]), array([0.35668496, 0.8217341 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09763357, 0.28816786]), 'bias': array([0.22633572])}, 'node_2': {'weights': array([0.18842499, 0.34212493]), 'bias': array([0.13424987])}}, 'output': {'node_1': {'weights': array([-0.09962909,  0.09567721]), 'bias': array([-0.65771183])}, 'node_2': {'weights': array([0.73132718, 0.9322762 ]), 'bias': array([0.57068705])}}}\n",
      "[array([0.1, 0.5]), array([0.59391724, 0.58033648]), array([0.34043456, 0.82434521])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09776873, 0.28884367]), 'bias': array([0.22768734])}, 'node_2': {'weights': array([0.18797144, 0.33985721]), 'bias': array([0.12971442])}}, 'output': {'node_1': {'weights': array([-0.12286807,  0.07296962]), 'bias': array([-0.69684014])}, 'node_2': {'weights': array([0.73781092, 0.93861167]), 'bias': array([0.58160396])}}}\n",
      "[array([0.1, 0.5]), array([0.59432791, 0.57894406]), array([0.3257175 , 0.82685633])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09790853, 0.28954263]), 'bias': array([0.22908527])}, 'node_2': {'weights': array([0.18755602, 0.33778009]), 'bias': array([0.12556017])}}, 'output': {'node_1': {'weights': array([-0.14446165,  0.05193498]), 'bias': array([-0.73317291])}, 'node_2': {'weights': array([0.74409767, 0.94473569]), 'bias': array([0.59218187])}}}\n",
      "[array([0.1, 0.5]), array([0.59475252, 0.57766757]), array([0.31236395, 0.82927235])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09805065, 0.29025327]), 'bias': array([0.23050654])}, 'node_2': {'weights': array([0.18717503, 0.33587514]), 'bias': array([0.12175028])}}, 'output': {'node_1': {'weights': array([-0.16457161,  0.0324027 ]), 'bias': array([-0.76698523])}, 'node_2': {'weights': array([0.75019718, 0.95065999]), 'bias': array([0.60243742])}}}\n",
      "[array([0.1, 0.5]), array([0.59518407, 0.57649598]), array([0.30021892, 0.83159791])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09819339, 0.29096697]), 'bias': array([0.23193393])}, 'node_2': {'weights': array([0.18682508, 0.33412539]), 'bias': array([0.11825078])}}, 'output': {'node_1': {'weights': array([-0.18334415,  0.0142196 ]), 'bias': array([-0.79852595])}, 'node_2': {'weights': array([0.75611856, 0.95639545]), 'bias': array([0.61238624])}}}\n",
      "[array([0.1, 0.5]), array([0.59561733, 0.57541908]), array([0.28914367, 0.83383742])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09833547, 0.29167734]), 'bias': array([0.23335468])}, 'node_2': {'weights': array([0.18650308, 0.3325154 ]), 'bias': array([0.1150308])}}, 'output': {'node_1': {'weights': array([-0.20091015, -0.00275072]), 'bias': array([-0.82801805])}, 'node_2': {'weights': array([0.7618703 , 0.96195214]), 'bias': array([0.62204302])}}}\n",
      "[array([0.1, 0.5]), array([0.59604842, 0.57442756]), array([0.2790155, 0.8359951])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09847594, 0.29237971]), 'bias': array([0.23475943])}, 'node_2': {'weights': array([0.18620626, 0.33103128]), 'bias': array([0.11206257])}}, 'output': {'node_1': {'weights': array([-0.21738615, -0.01862908]), 'bias': array([-0.85566011])}, 'node_2': {'weights': array([0.76746037, 0.96733943]), 'bias': array([0.63142156])}}}\n",
      "[array([0.1, 0.5]), array([0.59647452, 0.57351303]), array([0.26972674, 0.83807494])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09861415, 0.29307073]), 'bias': array([0.23614146])}, 'node_2': {'weights': array([0.18593213, 0.32966063]), 'bias': array([0.10932126])}}, 'output': {'node_1': {'weights': array([-0.23287559, -0.03352224]), 'bias': array([-0.88162841])}, 'node_2': {'weights': array([0.77289622, 0.97256603]), 'bias': array([0.64053486])}}}\n",
      "[array([0.1, 0.5]), array([0.59689358, 0.57266797]), array([0.26118329, 0.84008076])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.0987496 , 0.29374802]), 'bias': array([0.23749604])}, 'node_2': {'weights': array([0.18567847, 0.32839236]), 'bias': array([0.10678472])}}, 'output': {'node_1': {'weights': array([-0.2474701 , -0.04752442]), 'bias': array([-0.9060792])}, 'node_2': {'weights': array([0.77818485, 0.97764002]), 'bias': array([0.64939512])}}}\n",
      "[array([0.1, 0.5]), array([0.59730418, 0.57188566]), array([0.25330308, 0.84201616])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.098882  , 0.29440999]), 'bias': array([0.23881998])}, 'node_2': {'weights': array([0.18544333, 0.32721663]), 'bias': array([0.10443326])}}, 'output': {'node_1': {'weights': array([-0.26125094, -0.06071881]), 'bias': array([-0.92915092])}, 'node_2': {'weights': array([0.78333285, 0.98256894]), 'bias': array([0.65801385])}}}\n",
      "[array([0.1, 0.5]), array([0.59770536, 0.5711601 ]), array([0.24601459, 0.8438846 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09901112, 0.2950556 ]), 'bias': array([0.24011119])}, 'node_2': {'weights': array([0.18522494, 0.32612469]), 'bias': array([0.10224938])}}, 'output': {'node_1': {'weights': array([-0.27429013, -0.0731789 ]), 'bias': array([-0.95096634])}, 'node_2': {'weights': array([0.78834641, 0.98735984]), 'bias': array([0.66640185])}}}\n",
      "[array([0.1, 0.5]), array([0.5980965 , 0.57048598]), array([0.23925545, 0.84568931])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09913685, 0.29568425]), 'bias': array([0.2413685])}, 'node_2': {'weights': array([0.18502175, 0.32510875]), 'bias': array([0.1002175])}}, 'output': {'node_1': {'weights': array([-0.28665164, -0.08496976]), 'bias': array([-0.97163443])}, 'node_2': {'weights': array([0.79323134, 0.99201926]), 'bias': array([0.67456931])}}}\n",
      "[array([0.1, 0.5]), array([0.59847725, 0.56985855]), array([0.23297117, 0.84743338])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09925913, 0.29629567]), 'bias': array([0.24259134])}, 'node_2': {'weights': array([0.18483238, 0.32416189]), 'bias': array([0.09832378])}}, 'output': {'node_1': {'weights': array([-0.29839238, -0.09614906]), 'bias': array([-0.99125211])}, 'node_2': {'weights': array([0.79799312, 0.99655334]), 'bias': array([0.68252581])}}}\n",
      "[array([0.1, 0.5]), array([0.59884744, 0.56927357]), array([0.22711413, 0.84911971])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09937796, 0.29688982]), 'bias': array([0.24377964])}, 'node_2': {'weights': array([0.18465559, 0.32327794]), 'bias': array([0.09655588])}}, 'output': {'node_1': {'weights': array([-0.30956308, -0.1067681 ]), 'bias': array([-1.00990577])}, 'node_2': {'weights': array([0.80263694, 1.00096782]), 'bias': array([0.69028041])}}}\n",
      "[array([0.1, 0.5]), array([0.59920708, 0.56872729]), array([0.22164252, 0.85075105])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09949337, 0.29746685]), 'bias': array([0.24493369])}, 'node_2': {'weights': array([0.18449028, 0.32245139]), 'bias': array([0.09490278])}}, 'output': {'node_1': {'weights': array([-0.32020905, -0.11687254]), 'bias': array([-1.02767253])}, 'node_2': {'weights': array([0.80716767, 1.00526809]), 'bias': array([0.69784161])}}}\n",
      "[array([0.1, 0.5]), array([0.59955624, 0.56821633]), array([0.21651964, 0.85233001])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.0996054 , 0.29802702]), 'bias': array([0.24605403])}, 'node_2': {'weights': array([0.18433547, 0.32167733]), 'bias': array([0.09335466])}}, 'output': {'node_1': {'weights': array([-0.33037088, -0.1265032 ]), 'bias': array([-1.04462145])}, 'node_2': {'weights': array([0.81158991, 1.00945917]), 'bias': array([0.70521747])}}}\n",
      "[array([0.1, 0.5]), array([0.59989511, 0.56773768]), array([0.21171312, 0.85385902])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09971414, 0.29857069]), 'bias': array([0.24714139])}, 'node_2': {'weights': array([0.18419027, 0.32095135]), 'bias': array([0.0919027])}}, 'output': {'node_1': {'weights': array([-0.34008501, -0.1356966 ]), 'bias': array([-1.0608145])}, 'node_2': {'weights': array([0.81590802, 1.0135458 ]), 'bias': array([0.71241557])}}}\n",
      "[array([0.1, 0.5]), array([0.60022391, 0.56728866]), array([0.20719436, 0.8553404 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09981966, 0.29909831]), 'bias': array([0.24819662])}, 'node_2': {'weights': array([0.1840539, 0.3202695]), 'bias': array([0.090539])}}, 'output': {'node_1': {'weights': array([-0.34938422, -0.14448555]), 'bias': array([-1.07630741])}, 'node_2': {'weights': array([0.8201261 , 1.01753244]), 'bias': array([0.71944309])}}}\n",
      "[array([0.1, 0.5]), array([0.60054291, 0.56686682]), array([0.20293804, 0.85677633])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.09992207, 0.29961033]), 'bias': array([0.24922066])}, 'node_2': {'weights': array([0.18392565, 0.31962823]), 'bias': array([0.08925647])}}, 'output': {'node_1': {'weights': array([-0.35829809, -0.15289956]), 'bias': array([-1.09115043])}, 'node_2': {'weights': array([0.82424806, 1.02142325]), 'bias': array([0.72630681])}}}\n",
      "[array([0.1, 0.5]), array([0.6008524 , 0.56647001]), array([0.19892165, 0.85816888])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10002145, 0.30010725]), 'bias': array([0.2502145])}, 'node_2': {'weights': array([0.18380487, 0.31902435]), 'bias': array([0.0880487])}}, 'output': {'node_1': {'weights': array([-0.36685337, -0.16096528]), 'bias': array([-1.10538899])}, 'node_2': {'weights': array([0.82827758, 1.02522219]), 'bias': array([0.73301315])}}}\n",
      "[array([0.1, 0.5]), array([0.60115268, 0.56609624]), array([0.19512514, 0.85951999])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10011792, 0.30058959]), 'bias': array([0.25117917])}, 'node_2': {'weights': array([0.18369099, 0.31845496]), 'bias': array([0.08690992])}}, 'output': {'node_1': {'weights': array([-0.37507428, -0.16870679]), 'bias': array([-1.11906425])}, 'node_2': {'weights': array([0.83221815, 1.02893297]), 'bias': array([0.73956817])}}}\n",
      "[array([0.1, 0.5]), array([0.60144408, 0.56574376]), array([0.1915306 , 0.86083149])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10021157, 0.30105785]), 'bias': array([0.25211571])}, 'node_2': {'weights': array([0.18358349, 0.31791746]), 'bias': array([0.08583492])}}, 'output': {'node_1': {'weights': array([-0.38298287, -0.17614594]), 'bias': array([-1.13221357])}, 'node_2': {'weights': array([0.83607309, 1.03255908]), 'bias': array([0.74597764])}}}\n",
      "[array([0.1, 0.5]), array([0.60172691, 0.56541097]), array([0.18812198, 0.86210512])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10030251, 0.30151257]), 'bias': array([0.25302513])}, 'node_2': {'weights': array([0.1834819 , 0.31740949]), 'bias': array([0.08481898])}}, 'output': {'node_1': {'weights': array([-0.39059916, -0.18330257]), 'bias': array([-1.14487097])}, 'node_2': {'weights': array([0.83984553, 1.03610385]), 'bias': array([0.752247])}}}\n",
      "[array([0.1, 0.5]), array([0.60200149, 0.56509639]), array([0.1848849 , 0.86334251])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10039085, 0.30195423]), 'bias': array([0.25390846])}, 'node_2': {'weights': array([0.18338578, 0.31692889]), 'bias': array([0.08385779])}}, 'output': {'node_1': {'weights': array([-0.39794147, -0.19019477]), 'bias': array([-1.15706746])}, 'node_2': {'weights': array([0.84353846, 1.03957039]), 'bias': array([0.75838143])}}}\n",
      "[array([0.1, 0.5]), array([0.60226813, 0.56479873]), array([0.18180639, 0.86454522])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10047667, 0.30238335]), 'bias': array([0.2547667])}, 'node_2': {'weights': array([0.18329475, 0.31647373]), 'bias': array([0.08294746])}}, 'output': {'node_1': {'weights': array([-0.40502652, -0.19683903]), 'bias': array([-1.1688314])}, 'node_2': {'weights': array([0.84715472, 1.04296167]), 'bias': array([0.76438583])}}}\n",
      "[array([0.1, 0.5]), array([0.60252714, 0.56451677]), array([0.17887475, 0.86571471])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10056008, 0.3028004 ]), 'bias': array([0.25560079])}, 'node_2': {'weights': array([0.18320844, 0.31604222]), 'bias': array([0.08208443])}}, 'output': {'node_1': {'weights': array([-0.41186964, -0.20325045]), 'bias': array([-1.18018877])}, 'node_2': {'weights': array([0.850697  , 1.04628048]), 'bias': array([0.77026486])}}}\n",
      "[array([0.1, 0.5]), array([0.6027788 , 0.56424942]), array([0.17607942, 0.86685237])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10064117, 0.30320585]), 'bias': array([0.2564117])}, 'node_2': {'weights': array([0.18312655, 0.31563273]), 'bias': array([0.08126547])}}, 'output': {'node_1': {'weights': array([-0.4184849 , -0.20944287]), 'bias': array([-1.19116338])}, 'node_2': {'weights': array([0.85416787, 1.04952949]), 'bias': array([0.77602297])}}}\n",
      "[array([0.1, 0.5]), array([0.60302342, 0.56399569]), array([0.1734108 , 0.86795949])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10072003, 0.30360016]), 'bias': array([0.25720031])}, 'node_2': {'weights': array([0.18304876, 0.3152438 ]), 'bias': array([0.08048759])}}, 'output': {'node_1': {'weights': array([-0.42488527, -0.215429  ]), 'bias': array([-1.20177717])}, 'node_2': {'weights': array([0.85756976, 1.05271121]), 'bias': array([0.78166436])}}}\n",
      "[array([0.1, 0.5]), array([0.60326126, 0.56375466]), array([0.1708602 , 0.86903734])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10079675, 0.30398376]), 'bias': array([0.25796751])}, 'node_2': {'weights': array([0.18297481, 0.31487405]), 'bias': array([0.0797481])}}, 'output': {'node_1': {'weights': array([-0.43108265, -0.22122053]), 'bias': array([-1.21205031])}, 'node_2': {'weights': array([0.860905  , 1.05582803]), 'bias': array([0.78719305])}}}\n",
      "[array([0.1, 0.5]), array([0.6034926 , 0.56352549]), array([0.16841968, 0.87008707])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10087141, 0.30435707]), 'bias': array([0.25871413])}, 'node_2': {'weights': array([0.18290445, 0.31452225]), 'bias': array([0.0790445])}}, 'output': {'node_1': {'weights': array([-0.43708808, -0.22682824]), 'bias': array([-1.22200144])}, 'node_2': {'weights': array([0.86417581, 1.05888223]), 'bias': array([0.79261285])}}}\n",
      "[array([0.1, 0.5]), array([0.60371768, 0.56330742]), array([0.16608202, 0.87110982])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1009441 , 0.30472049]), 'bias': array([0.25944097])}, 'node_2': {'weights': array([0.18283745, 0.31418725]), 'bias': array([0.0783745])}}, 'output': {'node_1': {'weights': array([-0.44291174, -0.23226209]), 'bias': array([-1.23164777])}, 'node_2': {'weights': array([0.8673843 , 1.06187596]), 'bias': array([0.79792741])}}}\n",
      "[array([0.1, 0.5]), array([0.60393677, 0.56309975]), array([0.16384061, 0.87210662])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10101488, 0.30507441]), 'bias': array([0.26014881])}, 'node_2': {'weights': array([0.1827736 , 0.31386799]), 'bias': array([0.07773599])}}, 'output': {'node_1': {'weights': array([-0.44856307, -0.23753129]), 'bias': array([-1.24100525])}, 'node_2': {'weights': array([0.87053249, 1.06481127]), 'bias': array([0.80314019])}}}\n",
      "[array([0.1, 0.5]), array([0.60415008, 0.56290181]), array([0.1616894, 0.8730785])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10108384, 0.30541919]), 'bias': array([0.26083838])}, 'node_2': {'weights': array([0.1827127 , 0.31356352]), 'bias': array([0.07712704])}}, 'output': {'node_1': {'weights': array([-0.45405083, -0.24264437]), 'bias': array([-1.25008868])}, 'node_2': {'weights': array([0.87362231, 1.06769013]), 'bias': array([0.8082545])}}}\n",
      "[array([0.1, 0.5]), array([0.60435785, 0.56271302]), array([0.15962284, 0.87402639])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10115104, 0.30575519]), 'bias': array([0.26151038])}, 'node_2': {'weights': array([0.18265458, 0.31327292]), 'bias': array([0.07654585])}}, 'output': {'node_1': {'weights': array([-0.45938314, -0.24760924]), 'bias': array([-1.25891179])}, 'node_2': {'weights': array([0.87665558, 1.07051439]), 'bias': array([0.81327351])}}}\n",
      "[array([0.1, 0.5]), array([0.60456029, 0.56253281]), array([0.15763583, 0.87495121])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10121655, 0.30608274]), 'bias': array([0.26216549])}, 'node_2': {'weights': array([0.18259908, 0.31299539]), 'bias': array([0.07599077])}}, 'output': {'node_1': {'weights': array([-0.46456759, -0.25243328]), 'bias': array([-1.26748735])}, 'node_2': {'weights': array([0.87963409, 1.07328584]), 'bias': array([0.81820024])}}}\n",
      "[array([0.1, 0.5]), array([0.60475761, 0.56236069]), array([0.15572368, 0.87585381])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10128043, 0.30640217]), 'bias': array([0.26280434])}, 'node_2': {'weights': array([0.18254603, 0.31273014]), 'bias': array([0.07546028])}}, 'output': {'node_1': {'weights': array([-0.46961123, -0.25712334]), 'bias': array([-1.27582729])}, 'node_2': {'weights': array([0.88255949, 1.07600616]), 'bias': array([0.82303756])}}}\n",
      "[array([0.1, 0.5]), array([0.60495   , 0.56219618]), array([0.15388205, 0.87673502])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10134276, 0.30671378]), 'bias': array([0.26342755])}, 'node_2': {'weights': array([0.1824953 , 0.31247648]), 'bias': array([0.07495295])}}, 'output': {'node_1': {'weights': array([-0.47452065, -0.26168579]), 'bias': array([-1.2839427])}, 'node_2': {'weights': array([0.88543342, 1.07867697]), 'bias': array([0.82778824])}}}\n",
      "[array([0.1, 0.5]), array([0.60513765, 0.56203884]), array([0.15210695, 0.87759561])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10140357, 0.30701786]), 'bias': array([0.26403571])}, 'node_2': {'weights': array([0.18244675, 0.31223374]), 'bias': array([0.07446747])}}, 'output': {'node_1': {'weights': array([-0.479302  , -0.26612661]), 'bias': array([-1.29184397])}, 'node_2': {'weights': array([0.8882574 , 1.08129983]), 'bias': array([0.83245491])}}}\n",
      "[array([0.1, 0.5]), array([0.60532073, 0.56188826]), array([0.15039469, 0.87843632])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10146294, 0.30731469]), 'bias': array([0.26462937])}, 'node_2': {'weights': array([0.18240026, 0.31200131]), 'bias': array([0.07400262])}}, 'output': {'node_1': {'weights': array([-0.48396105, -0.27045137]), 'bias': array([-1.2995408])}, 'node_2': {'weights': array([0.89103291, 1.08387619]), 'bias': array([0.83704011])}}}\n",
      "[array([0.1, 0.5]), array([0.60549942, 0.56174407]), array([0.14874182, 0.87925786])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10152091, 0.30760453]), 'bias': array([0.26520906])}, 'node_2': {'weights': array([0.18235573, 0.31177863]), 'bias': array([0.07355726])}}, 'output': {'node_1': {'weights': array([-0.48850319, -0.27466528]), 'bias': array([-1.30704227])}, 'node_2': {'weights': array([0.89376138, 1.08640749]), 'bias': array([0.84154625])}}}\n",
      "[array([0.1, 0.5]), array([0.60567388, 0.56160592]), array([0.14714519, 0.88006091])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10157753, 0.30788765]), 'bias': array([0.2657753])}, 'node_2': {'weights': array([0.18231303, 0.31156517]), 'bias': array([0.07313033])}}, 'output': {'node_1': {'weights': array([-0.49293349, -0.27877323]), 'bias': array([-1.31435693])}, 'node_2': {'weights': array([0.89644415, 1.08889507]), 'bias': array([0.84597565])}}}\n",
      "[array([0.1, 0.5]), array([0.60584427, 0.56147347]), array([0.14560183, 0.88084609])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10163286, 0.30816428]), 'bias': array([0.26632856])}, 'node_2': {'weights': array([0.18227209, 0.31136043]), 'bias': array([0.07272086])}}, 'output': {'node_1': {'weights': array([-0.49725669, -0.28277981]), 'bias': array([-1.32149276])}, 'node_2': {'weights': array([0.89908253, 1.09134022]), 'bias': array([0.85033053])}}}\n",
      "[array([0.1, 0.5]), array([0.60601072, 0.56134643]), array([0.144109  , 0.88161403])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10168693, 0.30843465]), 'bias': array([0.26686931])}, 'node_2': {'weights': array([0.18223279, 0.31116396]), 'bias': array([0.07232791])}}, 'output': {'node_1': {'weights': array([-0.50147727, -0.28668932]), 'bias': array([-1.32845729])}, 'node_2': {'weights': array([0.90167777, 1.09374418]), 'bias': array([0.85461303])}}}\n",
      "[array([0.1, 0.5]), array([0.60617339, 0.56122451]), array([0.14266414, 0.88236531])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1017398 , 0.30869899]), 'bias': array([0.26739799])}, 'node_2': {'weights': array([0.18219506, 0.31097532]), 'bias': array([0.07195064])}}, 'output': {'node_1': {'weights': array([-0.50559944, -0.29050583]), 'bias': array([-1.3352576])}, 'node_2': {'weights': array([0.90423106, 1.09610815]), 'bias': array([0.85882518])}}}\n",
      "[array([0.1, 0.5]), array([0.6063324 , 0.56110745]), array([0.14126487, 0.88310048])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1017915 , 0.30895751]), 'bias': array([0.26791502])}, 'node_2': {'weights': array([0.18215882, 0.31079411]), 'bias': array([0.07158823])}}, 'output': {'node_1': {'weights': array([-0.50962715, -0.29423313]), 'bias': array([-1.34190036])}, 'node_2': {'weights': array([0.90674358, 1.09843326]), 'bias': array([0.86296897])}}}\n",
      "[array([0.1, 0.5]), array([0.60648789, 0.56099499]), array([0.13990895, 0.88382008])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10184208, 0.3092104 ]), 'bias': array([0.26842081])}, 'node_2': {'weights': array([0.18212399, 0.31061997]), 'bias': array([0.07123994])}}, 'output': {'node_1': {'weights': array([-0.51356416, -0.29787482]), 'bias': array([-1.34839184])}, 'node_2': {'weights': array([0.90921641, 1.1007206 ]), 'bias': array([0.86704627])}}}\n",
      "[array([0.1, 0.5]), array([0.60663998, 0.56088691]), array([0.13859432, 0.88452463])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10189157, 0.30945787]), 'bias': array([0.26891573])}, 'node_2': {'weights': array([0.18209051, 0.31045253]), 'bias': array([0.07090507])}}, 'output': {'node_1': {'weights': array([-0.51741399, -0.30143429]), 'bias': array([-1.35473799])}, 'node_2': {'weights': array([0.91165063, 1.10297123]), 'bias': array([0.87105889])}}}\n",
      "[array([0.1, 0.5]), array([0.60678878, 0.56078299]), array([0.13731901, 0.8852146 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10194002, 0.30970008]), 'bias': array([0.26940016])}, 'node_2': {'weights': array([0.18205829, 0.31029147]), 'bias': array([0.07058295])}}, 'output': {'node_1': {'weights': array([-0.52117997, -0.30491474]), 'bias': array([-1.36094441])}, 'node_2': {'weights': array([0.91404726, 1.10518615]), 'bias': array([0.87500859])}}}\n",
      "[array([0.1, 0.5]), array([0.6069344 , 0.56068302]), array([0.1360812 , 0.88589046])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10198745, 0.30993723]), 'bias': array([0.26987445])}, 'node_2': {'weights': array([0.1820273 , 0.31013648]), 'bias': array([0.07027296])}}, 'output': {'node_1': {'weights': array([-0.52486527, -0.3083192 ]), 'bias': array([-1.36701639])}, 'node_2': {'weights': array([0.91640729, 1.10736633]), 'bias': array([0.87889703])}}}\n",
      "[array([0.1, 0.5]), array([0.60707696, 0.56058681]), array([0.13487919, 0.88655266])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10203389, 0.31016947]), 'bias': array([0.27033894])}, 'node_2': {'weights': array([0.18199745, 0.30998726]), 'bias': array([0.06997453])}}, 'output': {'node_1': {'weights': array([-0.52847287, -0.31165053]), 'bias': array([-1.37295896])}, 'node_2': {'weights': array([0.91873167, 1.10951271]), 'bias': array([0.88272584])}}}\n",
      "[array([0.1, 0.5]), array([0.60721655, 0.56049418]), array([0.13371136, 0.88720163])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10207939, 0.31039697]), 'bias': array([0.27079393])}, 'node_2': {'weights': array([0.18196871, 0.30984355]), 'bias': array([0.0696871])}}, 'output': {'node_1': {'weights': array([-0.53200559, -0.31491143]), 'bias': array([-1.37877687])}, 'node_2': {'weights': array([0.92102131, 1.11162618]), 'bias': array([0.88649656])}}}\n",
      "[array([0.1, 0.5]), array([0.60735328, 0.56040497]), array([0.1325762 , 0.88783777])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10212398, 0.31061988]), 'bias': array([0.27123975])}, 'node_2': {'weights': array([0.18194102, 0.30970509]), 'bias': array([0.06941017])}}, 'output': {'node_1': {'weights': array([-0.53546614, -0.31810447]), 'bias': array([-1.38447461])}, 'node_2': {'weights': array([0.92327711, 1.1137076 ]), 'bias': array([0.8902107])}}}\n",
      "[array([0.1, 0.5]), array([0.60748723, 0.560319  ]), array([0.13147228, 0.88846148])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10216767, 0.31083835]), 'bias': array([0.27167669])}, 'node_2': {'weights': array([0.18191432, 0.30957162]), 'bias': array([0.06914325])}}, 'output': {'node_1': {'weights': array([-0.53885705, -0.32123209]), 'bias': array([-1.39005647])}, 'node_2': {'weights': array([0.9254999 , 1.11575781]), 'bias': array([0.8938697])}}}\n",
      "[array([0.1, 0.5]), array([0.6076185 , 0.56023615]), array([0.13039828, 0.88907314])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1022105 , 0.31105252]), 'bias': array([0.27210503])}, 'node_2': {'weights': array([0.18188859, 0.30944294]), 'bias': array([0.06888588])}}, 'output': {'node_1': {'weights': array([-0.54218074, -0.32429661]), 'bias': array([-1.39552651])}, 'node_2': {'weights': array([0.92769051, 1.1177776 ]), 'bias': array([0.89747494])}}}\n",
      "[array([0.1, 0.5]), array([0.60774717, 0.56015625]), array([0.12935293, 0.8896731 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1022525 , 0.31126252]), 'bias': array([0.27252504])}, 'node_2': {'weights': array([0.18186376, 0.30931882]), 'bias': array([0.06863763])}}, 'output': {'node_1': {'weights': array([-0.54543953, -0.3273002 ]), 'bias': array([-1.40088858])}, 'node_2': {'weights': array([0.92984973, 1.11976773]), 'bias': array([0.90102776])}}}\n",
      "[array([0.1, 0.5]), array([0.60787332, 0.56007918]), array([0.12833504, 0.89026172])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1022937 , 0.31146849]), 'bias': array([0.27293697])}, 'node_2': {'weights': array([0.18183981, 0.30919905]), 'bias': array([0.0683981])}}, 'output': {'node_1': {'weights': array([-0.54863559, -0.33024498]), 'bias': array([-1.40614636])}, 'node_2': {'weights': array([0.93197833, 1.12172897]), 'bias': array([0.90452947])}}}\n",
      "[array([0.1, 0.5]), array([0.60799703, 0.56000482]), array([0.12734349, 0.89083932])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10233411, 0.31167054]), 'bias': array([0.27334109])}, 'node_2': {'weights': array([0.18181669, 0.30908345]), 'bias': array([0.0681669])}}, 'output': {'node_1': {'weights': array([-0.55177102, -0.33313291]), 'bias': array([-1.41130334])}, 'node_2': {'weights': array([0.93407703, 1.12366201]), 'bias': array([0.90798131])}}}\n",
      "[array([0.1, 0.5]), array([0.60811838, 0.55993304]), array([0.12637721, 0.89140623])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10237376, 0.31186881]), 'bias': array([0.27373761])}, 'node_2': {'weights': array([0.18179437, 0.30897183]), 'bias': array([0.06794367])}}, 'output': {'node_1': {'weights': array([-0.55484779, -0.33596589]), 'bias': array([-1.41636284])}, 'node_2': {'weights': array([0.93614656, 1.12556756]), 'bias': array([0.91138447])}}}\n",
      "[array([0.1, 0.5]), array([0.60823744, 0.55986373]), array([0.12543519, 0.89196275])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10241268, 0.31206339]), 'bias': array([0.27412678])}, 'node_2': {'weights': array([0.18177281, 0.30886403]), 'bias': array([0.06772806])}}, 'output': {'node_1': {'weights': array([-0.55786781, -0.33874572]), 'bias': array([-1.42132804])}, 'node_2': {'weights': array([0.9381876 , 1.12744627]), 'bias': array([0.91474014])}}}\n",
      "[array([0.1, 0.5]), array([0.60835428, 0.55979678]), array([0.1245165 , 0.89250918])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10245088, 0.31225441]), 'bias': array([0.27450881])}, 'node_2': {'weights': array([0.18175198, 0.30875988]), 'bias': array([0.06751976])}}, 'output': {'node_1': {'weights': array([-0.56083288, -0.34147413]), 'bias': array([-1.42620196])}, 'node_2': {'weights': array([0.94020082, 1.1292988 ]), 'bias': array([0.91804942])}}}\n",
      "[array([0.1, 0.5]), array([0.60846896, 0.55973211]), array([0.12362022, 0.89304581])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10248839, 0.31244196]), 'bias': array([0.27488391])}, 'node_2': {'weights': array([0.18173185, 0.30865923]), 'bias': array([0.06731845])}}, 'output': {'node_1': {'weights': array([-0.56374473, -0.34415275]), 'bias': array([-1.43098749])}, 'node_2': {'weights': array([0.94218685, 1.13112576]), 'bias': array([0.92131341])}}}\n",
      "[array([0.1, 0.5]), array([0.60858155, 0.5596696 ]), array([0.12274551, 0.8935729 ])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10252523, 0.31262614]), 'bias': array([0.27525229])}, 'node_2': {'weights': array([0.18171239, 0.30856193]), 'bias': array([0.06712385])}}, 'output': {'node_1': {'weights': array([-0.566605  , -0.34678314]), 'bias': array([-1.43568739])}, 'node_2': {'weights': array([0.94414633, 1.13292775]), 'bias': array([0.92453315])}}}\n",
      "[array([0.1, 0.5]), array([0.60869211, 0.55960917]), array([0.12189155, 0.89409072])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10256141, 0.31280707]), 'bias': array([0.27561413])}, 'node_2': {'weights': array([0.18169357, 0.30846784]), 'bias': array([0.06693568])}}, 'output': {'node_1': {'weights': array([-0.56941528, -0.3493668 ]), 'bias': array([-1.44030429])}, 'node_2': {'weights': array([0.94607985, 1.13470535]), 'bias': array([0.92770966])}}}\n",
      "[array([0.1, 0.5]), array([0.6088007 , 0.55955074]), array([0.12105757, 0.89459952])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10259696, 0.31298482]), 'bias': array([0.27596963])}, 'node_2': {'weights': array([0.18167537, 0.30837683]), 'bias': array([0.06675367])}}, 'output': {'node_1': {'weights': array([-0.57217706, -0.35190516]), 'bias': array([-1.44484072])}, 'node_2': {'weights': array([0.94798799, 1.13645914]), 'bias': array([0.93084393])}}}\n",
      "[array([0.1, 0.5]), array([0.60890737, 0.55949422]), array([0.12024285, 0.89509955])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1026319 , 0.31315948]), 'bias': array([0.27631897])}, 'node_2': {'weights': array([0.18165776, 0.30828879]), 'bias': array([0.06657757])}}, 'output': {'node_1': {'weights': array([-0.57489179, -0.35439959]), 'bias': array([-1.44929909])}, 'node_2': {'weights': array([0.94987132, 1.13818963]), 'bias': array([0.9339369])}}}\n",
      "[array([0.1, 0.5]), array([0.60901219, 0.55943953]), array([0.11944669, 0.89559104])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10266623, 0.31333115]), 'bias': array([0.2766623])}, 'node_2': {'weights': array([0.18164072, 0.30820358]), 'bias': array([0.06640716])}}, 'output': {'node_1': {'weights': array([-0.57756085, -0.35685139]), 'bias': array([-1.45368169])}, 'node_2': {'weights': array([0.95173039, 1.13989738]), 'bias': array([0.9369895])}}}\n",
      "[array([0.1, 0.5]), array([0.6091152 , 0.55938661]), array([0.11866842, 0.89607422])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10269998, 0.31349991]), 'bias': array([0.27699982])}, 'node_2': {'weights': array([0.18162422, 0.3081211 ]), 'bias': array([0.06624221])}}, 'output': {'node_1': {'weights': array([-0.58018556, -0.35926183]), 'bias': array([-1.45799076])}, 'node_2': {'weights': array([0.95356572, 1.14158287]), 'bias': array([0.94000261])}}}\n",
      "[array([0.1, 0.5]), array([0.60921644, 0.55933538]), array([0.11790743, 0.89654931])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10273317, 0.31366583]), 'bias': array([0.27733166])}, 'node_2': {'weights': array([0.18160825, 0.30804125]), 'bias': array([0.0660825])}}, 'output': {'node_1': {'weights': array([-0.5827672 , -0.36163209]), 'bias': array([-1.46222839])}, 'node_2': {'weights': array([0.95537783, 1.14324661]), 'bias': array([0.94297709])}}}\n",
      "[array([0.1, 0.5]), array([0.60931598, 0.55928578]), array([0.1171631 , 0.89701652])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1027658, 0.313829 ]), 'bias': array([0.27765799])}, 'node_2': {'weights': array([0.18159278, 0.30796391]), 'bias': array([0.06592782])}}, 'output': {'node_1': {'weights': array([-0.58530698, -0.36396333]), 'bias': array([-1.46639664])}, 'node_2': {'weights': array([0.95716721, 1.14488906]), 'bias': array([0.9459138])}}}\n",
      "[array([0.1, 0.5]), array([0.60941386, 0.55923774]), array([0.11643488, 0.89747604])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.1027979 , 0.31398948]), 'bias': array([0.27797896])}, 'node_2': {'weights': array([0.1815778, 0.307889 ]), 'bias': array([0.065778])}}, 'output': {'node_1': {'weights': array([-0.58780607, -0.36625665]), 'bias': array([-1.47049744])}, 'node_2': {'weights': array([0.95893434, 1.1465107 ]), 'bias': array([0.94881352])}}}\n",
      "[array([0.1, 0.5]), array([0.60951012, 0.55919121]), array([0.11572221, 0.89792809])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10282947, 0.31414735]), 'bias': array([0.2782947])}, 'node_2': {'weights': array([0.18156328, 0.30781642]), 'bias': array([0.06563283])}}, 'output': {'node_1': {'weights': array([-0.59026559, -0.36851312]), 'bias': array([-1.47453268])}, 'node_2': {'weights': array([0.9606797 , 1.14811196]), 'bias': array([0.95167706])}}}\n",
      "[array([0.1, 0.5]), array([0.6096048 , 0.55914612]), array([0.11502457, 0.89837284])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10286054, 0.31430268]), 'bias': array([0.27860536])}, 'node_2': {'weights': array([0.18154922, 0.30774608]), 'bias': array([0.06549216])}}, 'output': {'node_1': {'weights': array([-0.59268661, -0.37073375]), 'bias': array([-1.47850414])}, 'node_2': {'weights': array([0.96240372, 1.14969329]), 'bias': array([0.95450516])}}}\n",
      "[array([0.1, 0.5]), array([0.60969795, 0.55910243]), array([0.11434148, 0.89881048])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10289111, 0.31445553]), 'bias': array([0.27891107])}, 'node_2': {'weights': array([0.18153558, 0.3076779 ]), 'bias': array([0.0653558])}}, 'output': {'node_1': {'weights': array([-0.59507017, -0.37291951]), 'bias': array([-1.48241356])}, 'node_2': {'weights': array([0.96410686, 1.15125509]), 'bias': array([0.95729858])}}}\n",
      "[array([0.1, 0.5]), array([0.60978961, 0.55906008]), array([0.11367244, 0.89924119])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10292119, 0.31460597]), 'bias': array([0.27921195])}, 'node_2': {'weights': array([0.18152236, 0.3076118 ]), 'bias': array([0.0652236])}}, 'output': {'node_1': {'weights': array([-0.59741728, -0.37507136]), 'bias': array([-1.4862626])}, 'node_2': {'weights': array([0.96578955, 1.15279779]), 'bias': array([0.96005803])}}}\n",
      "[array([0.1, 0.5]), array([0.60987981, 0.55901902]), array([0.11301702, 0.89966514])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10295081, 0.31475406]), 'bias': array([0.27950813])}, 'node_2': {'weights': array([0.18150954, 0.3075477 ]), 'bias': array([0.06509541])}}, 'output': {'node_1': {'weights': array([-0.59972888, -0.37719018]), 'bias': array([-1.49005285])}, 'node_2': {'weights': array([0.96745218, 1.15432177]), 'bias': array([0.9627842])}}}\n",
      "[array([0.1, 0.5]), array([0.6099686, 0.5589792]), array([0.11237478, 0.90008249])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10297997, 0.31489986]), 'bias': array([0.27979973])}, 'node_2': {'weights': array([0.18149711, 0.30748554]), 'bias': array([0.06497108])}}, 'output': {'node_1': {'weights': array([-0.60200589, -0.37927685]), 'bias': array([-1.49378586])}, 'node_2': {'weights': array([0.96909517, 1.15582742]), 'bias': array([0.96547777])}}}\n",
      "[array([0.1, 0.5]), array([0.61005601, 0.55894058]), array([0.1117453 , 0.90049341])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10300869, 0.31504343]), 'bias': array([0.28008686])}, 'node_2': {'weights': array([0.18148505, 0.30742524]), 'bias': array([0.06485047])}}, 'output': {'node_1': {'weights': array([-0.60424922, -0.38133221]), 'bias': array([-1.4974631])}, 'node_2': {'weights': array([0.97071891, 1.15731511]), 'bias': array([0.96813939])}}}\n",
      "[array([0.1, 0.5]), array([0.61014207, 0.55890311]), array([0.11112818, 0.90089804])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10303696, 0.31518482]), 'bias': array([0.28036963])}, 'node_2': {'weights': array([0.18147335, 0.30736673]), 'bias': array([0.06473345])}}, 'output': {'node_1': {'weights': array([-0.6064597 , -0.38335706]), 'bias': array([-1.501086])}, 'node_2': {'weights': array([0.97232378, 1.1587852 ]), 'bias': array([0.97076971])}}}\n",
      "[array([0.1, 0.5]), array([0.61022682, 0.55886677]), array([0.11052305, 0.90129654])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10306482, 0.31532408]), 'bias': array([0.28064816])}, 'node_2': {'weights': array([0.18146199, 0.30730995]), 'bias': array([0.0646199])}}, 'output': {'node_1': {'weights': array([-0.60863816, -0.38535218]), 'bias': array([-1.50465593])}, 'node_2': {'weights': array([0.97391014, 1.16023805]), 'bias': array([0.97336933])}}}\n",
      "[array([0.1, 0.5]), array([0.61031029, 0.55883149]), array([0.10992954, 0.90168905])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10309225, 0.31546127]), 'bias': array([0.28092255])}, 'node_2': {'weights': array([0.18145097, 0.30725484]), 'bias': array([0.06450968])}}, 'output': {'node_1': {'weights': array([-0.61078541, -0.38731831]), 'bias': array([-1.50817421])}, 'node_2': {'weights': array([0.97547836, 1.16167399]), 'bias': array([0.97593887])}}}\n",
      "[array([0.1, 0.5]), array([0.61039251, 0.55879725]), array([0.10934731, 0.90207571])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10311929, 0.31559644]), 'bias': array([0.28119288])}, 'node_2': {'weights': array([0.18144027, 0.30720135]), 'bias': array([0.0644027])}}, 'output': {'node_1': {'weights': array([-0.6129022 , -0.38925617]), 'bias': array([-1.51164213])}, 'node_2': {'weights': array([0.97702878, 1.16309335]), 'bias': array([0.97847891])}}}\n",
      "[array([0.1, 0.5]), array([0.61047351, 0.55876402]), array([0.108776  , 0.90245666])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10314593, 0.31572964]), 'bias': array([0.28145928])}, 'node_2': {'weights': array([0.18142988, 0.30714941]), 'bias': array([0.06429882])}}, 'output': {'node_1': {'weights': array([-0.61498928, -0.39116646]), 'bias': array([-1.51506091])}, 'node_2': {'weights': array([0.97856174, 1.16449647]), 'bias': array([0.98099002])}}}\n",
      "[array([0.1, 0.5]), array([0.61055333, 0.55873175]), array([0.10821532, 0.90283202])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10317218, 0.31586091]), 'bias': array([0.28172181])}, 'node_2': {'weights': array([0.1814198 , 0.30709898]), 'bias': array([0.06419796])}}, 'output': {'node_1': {'weights': array([-0.61704735, -0.39304985]), 'bias': array([-1.51843174])}, 'node_2': {'weights': array([0.98007758, 1.16588365]), 'bias': array([0.98347274])}}}\n",
      "[array([0.1, 0.5]), array([0.61063198, 0.55870042]), array([0.10766494, 0.90320193])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10319806, 0.31599029]), 'bias': array([0.28198059])}, 'node_2': {'weights': array([0.18141, 0.30705]), 'bias': array([0.0641])}}, 'output': {'node_1': {'weights': array([-0.61907711, -0.39490699]), 'bias': array([-1.52175578])}, 'node_2': {'weights': array([0.98157661, 1.16725519]), 'bias': array([0.98592763])}}}\n",
      "[array([0.1, 0.5]), array([0.6107095 , 0.55866998]), array([0.10712457, 0.90356651])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10322357, 0.31611784]), 'bias': array([0.28223569])}, 'node_2': {'weights': array([0.18140048, 0.30700242]), 'bias': array([0.06400484])}}, 'output': {'node_1': {'weights': array([-0.62107922, -0.3967385 ]), 'bias': array([-1.52503412])}, 'node_2': {'weights': array([0.98305915, 1.1686114 ]), 'bias': array([0.98835519])}}}\n",
      "[array([0.1, 0.5]), array([0.61078591, 0.55864042]), array([0.10659392, 0.90392588])]\n",
      "[0.05 0.95]\n",
      "0.6\n",
      "{'layer_1': {'node_1': {'weights': array([0.10324872, 0.3162436 ]), 'bias': array([0.2824872])}, 'node_2': {'weights': array([0.18139124, 0.3069562 ]), 'bias': array([0.0639124])}}, 'output': {'node_1': {'weights': array([-0.62305434, -0.39854499]), 'bias': array([-1.52826784])}, 'node_2': {'weights': array([0.98452549, 1.16995255]), 'bias': array([0.99075594])}}}\n",
      "[array([0.1, 0.5]), array([0.61086125, 0.5586117 ]), array([0.10607272, 0.90428016])]\n",
      "[0.05 0.95]\n",
      "0.6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error (MSE) loss.\n",
    "    Arguments:\n",
    "        y_true: Ground truth labels (numpy array).\n",
    "        y_pred: Predicted output from the network (numpy array).\n",
    "    Returns:\n",
    "        Mean Squared Error (scalar value).\n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Loop\n",
    "losses = []  # List to store the loss at each iteration\n",
    "learning_rate = 0.6  # Learning rate for weight updates\n",
    "\n",
    "# Iterate over the number of training steps (100 iterations in this case)\n",
    "for iteration in range(100):\n",
    "    # Step 1: Perform forward propagation to compute the network's predictions\n",
    "    activations = forward_propagationS(network, inputs)  # Forward pass\n",
    "    \n",
    "    # Step 2: Compute the loss (error) between the true labels and the predicted output\n",
    "    loss = compute_loss(y_true, activations[-1])  # Loss for the current iteration\n",
    "    losses.append(loss)  # Append the computed loss to the list\n",
    "    \n",
    "    # Step 3: Perform backpropagation to compute gradients and update weights\n",
    "    network = backpropagation_with_updates(network, activations, y_true, learning_rate)\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(losses)  \n",
    "plt.title(\"Jace Marden + Loss Before and After Weight Updates\") \n",
    "plt.xlabel(\"Iterations\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
